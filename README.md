### DOGGY AND CAT ADVENTURE

## Structure

```sh
backend/
â”œâ”€â”€ archive/                       # Legcy code
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ test/
â”œâ”€â”€ logs/                         # Logs de l'entraÃ®nement / infÃ©rence
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ image_model/              # ModÃ¨les et scripts liÃ©s aux images
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ test.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ audio_model/              # ModÃ¨les et scripts liÃ©s Ã  l'audio
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ test.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ multimodal/               # Fusion multimodale image + audio
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â””â”€â”€ inference/                # Inference centralisÃ©e
â”‚       â”œâ”€â”€ predictor.py
â”‚       â””â”€â”€ utils.py
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                      # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ endpoints.py
â”‚   â””â”€â”€ tests/                    # Tests de l'application
â”‚       â”œâ”€â”€ test_api.py
â”‚       â””â”€â”€ test_models.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ logger_config.py
â”œâ”€â”€ wandb/                        # GÃ©nÃ©rÃ© automatiquement par WandB
â”œâ”€â”€ models/                       # ModÃ¨les entraÃ®nÃ©s (sauvegarde .keras, .h5, etc.)
â”œâ”€â”€ monitoring/                   # Prometheus, Grafana, scripts de dÃ©ploiement monitoring
â”œâ”€â”€ .github/workflows/            # GitHub Actions (CI/CD)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py                       # Point dâ€™entrÃ©e global
frontend/                         # Frontend (streamlit, react, autre)
```

## Installation

**Clone this repository**

```bash
git clone https://github.com/elpulpo0/[...].git
```

**Create a virtual environnement**

```bash
python -m venv .venv
```

**Connect to the virtual environnement**

```bash
source .venv/Scripts/activate
```

**Upgrade pip and install librairies**

```bash
python.exe -m pip install --upgrade pip
```

```bash
pip install -r requirements.txt
```

Open 2 different terminals:

## Lancer le projet â€“ Backend (Terminal 1)

```bash
cd backend
```

### Connexion aux services externes

* **Kaggle** : place ton fichier `kaggle.json` dans `~/.kaggle/`
  (obtenu sur [https://www.kaggle.com/account](https://www.kaggle.com/account) â†’ "Create API Token")
* **WandB** (si utilisÃ©) :

```bash
wandb login
```

---

### TÃ©lÃ©charger les donnÃ©es

```bash
python -m scripts.download_datas
```

### EntraÃ®ner les modÃ¨les image/audio

```bash
python -m scripts.run_train_and_test
```

---

### Lancer lâ€™API FastAPI

```bash
uvicorn main:app --reload
```

Cela dÃ©marre une API REST sur :

* Swagger UI : [http://localhost:8000/docs](http://localhost:8000/docs)
* Endpoint actif : `POST /predict/image`
  â†’ prend un fichier `.jpg/.png` et retourne `{"prediction": ..., "confidence": ...}`

---

## Frontend Streamlit (Terminal 2)

```bash
cd frontend
streamlit run app.py
```

### Ce que fait l'interface :

* Permet dâ€™**uploader une image**
* Affiche lâ€™image avec une **animation stylÃ©e (Lottie)**
* Envoie la requÃªte Ã  lâ€™API FastAPI `/predict/image`
* Affiche la **prÃ©diction** (`Chien` ou `Chat`) + **niveau de confiance (%)**
* Barre de progression + messages UX pour guider lâ€™utilisateur

---

### Interface avec 3 onglets : Image ðŸ–¼ï¸, Audio ðŸŽµ, Multimodal ðŸ§¹

* Upload fichiers
* Appel Ã  lâ€™API appropriÃ©e
* Affichage prÃ©diction + confiance + UX animÃ©e

---

### Ã€ noter :

* Le frontend Streamlit ne contient pas de logique mÃ©tier : il **consomme lâ€™API backend**.
* Le modÃ¨le est chargÃ© cÃ´tÃ© FastAPI pour des raisons de sÃ©curitÃ© et de scalabilitÃ©.
* Lâ€™infÃ©rence est centralisÃ©e pour un futur support audio/multimodal.

---

## ModÃ¨les IA

| Type       | ModÃ¨le                      | DÃ©tail                                 |
| ---------- | --------------------------- | -------------------------------------- |
| Image      | MobileNetV2                 | Fine-tunÃ© sur images chiens/chats      |
| Audio      | YAMNet                      | Classifie aboiement vs miaulement      |
| Multimodal | Fusion MobileNetV2 + YAMNet | Fusion Dense sur embeddings concatÃ©nÃ©s |

---

## Avancement

* âœ… ModÃ¨les image/audio/multimodal prÃªts
* âœ… API FastAPI avec endpoints actifs
* âœ… Streamlit avec 3 modes fonctionnels
* âœ… Bonne prÃ©cision (multimodal > 95 %)

---

## Prochaines Ã©tapes

* ðŸ”¹ Ajout dâ€™un benchmark comparatif
* ðŸ”¹ Nettoyage des fichiers orphelins
* ðŸ”¹ PrÃ©diction "aucun des deux"
* ðŸ”¹ DÃ©ploiement cloud (Render / HF Spaces)

---

## Stack technique

| Composant | Tech                        |
| --------- | --------------------------- |
| Backend   | FastAPI, TensorFlow, YAMNet |
| Frontend  | Streamlit, Lottie           |
| ModÃ¨les   | CNN, MobileNetV2, YAMNet    |
| CI/CD     | GitHub Actions              |

---

## CrÃ©dits

Projet rÃ©alisÃ© dans le cadre de la formation de \[DÃ©veloppeur en Intelligence Artificielle] Ã  \[Simplon.co]
- Mathieu Soussignan
- Chris El-Pulpo
- Arnaud Boy
- Anthony Vallad